#my final attempt


import random
import numpy as np
import math
import tensorflow as tf
from tensorflow.keras.datasets import mnist

import PIL
from PIL import Image

#my data set
myTest = Image.open(r"C:\Users\david\OneDrive\Pictures\Screenshots\whiteout3.png")
#myTest.resize(100,100)

def prepare_personal_sample(file):
    image = Image.open(file)

    MNIST_size = (28, 28)
    image = image.resize(MNIST_size)

    image = image.convert('L')#greyscale

    pixelVal_list = list(image.getdata())#length of 784

    for i in range(len(pixelVal_list)):
        pixelVal_list[i] = np.abs(pixelVal_list[i] - 255)#final color invert
    
    image_array = np.array(pixelVal_list)

    return image_array
    

image3array = prepare_personal_sample(r"C:\Users\david\OneDrive\Pictures\Screenshots\whiteout3.png")
image4array = prepare_personal_sample(r"C:\Users\david\OneDrive\Pictures\Screenshots\whiteout4.png")
image8array = prepare_personal_sample(r"C:\Users\david\OneDrive\Pictures\Screenshots\whiteout8.png")


(trainImage, trainLabel), (testImage, testLabel) = mnist.load_data()


#make np arrays
trainImage = np.array(trainImage)
#the labels are just lists of the numbers that the images are of
testImage = np.array(testImage)

Y_dev = testLabel
X_dev = testImage

Y_train = trainLabel
X_train = trainImage

#REFORMATTING TRAINING IMAGES
reformatted = np.zeros((60000,784))
localRow = []
counter = 0;
for image in trainImage:#(s)
    for row in image:#(image)
        for item in row:
            localRow.append(item)   #scalling it down, so a 255 would = 1         
    reformatted[counter] = localRow
    localRow = []
    counter += 1

X_train = reformatted
X_train = X_train / 255


#REFORMATTING TESTING IMAGES
reformattedTest = np.zeros((60000,784))
localRowTest = []
counterTest = 0;
for imageTest in testImage:#(s)
    for rowTest in imageTest:#(image)
        for itemTest in rowTest:
            localRowTest.append(itemTest)   #scalling it down, so a 255 would = 1         
    reformattedTest[counterTest] = localRowTest
    localRowTest = []
    counterTest += 1

X_dev = reformattedTest
X_dev = X_dev / 255
'''End dev format'''





print(X_train[0].shape)
#makes groups of 784row * 1colm matrixes 
      
def init_params():
    #weights for fiirst layer
    W1 = np.random.rand(10,784) - 0.5 #between -0.5 and 0.5
    b1 = np.random.rand(10,1) - 0.5
    W2 = np.random.rand(10,10) - 0.5
    b2 = np.random.rand(10,1) - 0.5
    return W1, b1, W2, b2


#ACTIVATION FUNCTIONS
def ReLU(Z):
    return np.maximum(0, Z)

def deriv_ReLU(z):
    return z > 0;

def sigmoid(z):
    """The sigmoid function."""

    z = z/(max(abs(z )))

    return 1.0/(1.0+np.exp(-z))


def sigmoid_prime(z):
    """Derivative of the sigmoid function."""
    return sigmoid(z)*(1-sigmoid(z))



def softmax(z):#not exactly sure how this one works
    A = np.exp(z) / sum(np.exp(z))

    
    return A


def forward_prop(W1, b1, W2, b2, X): #applying everything forwards
    #calculate that value
    #where X is a 784 by 1 of the pixels, need to figure out how to do that part

    
    Z1 = W1.dot(X) + b1
    '''print("Z1")
    print(Z1.shape)'''
    
    #A1 = ReLU(Z1)
    A1 = sigmoid(Z1) #sigmoid activation
    '''print("A2")
    #print(A1)'''
    
    Z2 = W2.dot(A1) + b2
    #print(Z2)
    A2 = softmax(Z2)
    

    return Z1, A1, Z2, A2


def one_hot(Y):
    #creating a matrix like so: [0,0,1,0....0] , in that case, the label is "2"
    #Y is the labeling set
    one_hot_Y = np.zeros((Y.size, 10))#Y.max() + 1))#+1 bc we are starting w/ 0 as digit
    one_hot_Y[np.arange(Y.size), Y] = 1
    one_hot_Y = one_hot_Y.T #transposed
    #go to that row, and for that row val (0-9), set that one = TO Y (0-9)
    #each collumn is the onehot for each image I think

    return one_hot_Y

    

def back_prop(Z1, A1, Z2, A2, W2, X, Y):
    m = Y.size #size of Y, labels
    
    one_hot_Y = one_hot(Y)
    dZ2 = A2 - one_hot_Y # error I think? Why not error squared??
    dW2 = 1 / m * dZ2.dot(A1.T) # a learning rate 1/m proportional to size??
    db2 = 1 / m * np.sum(dZ2)#what is the 2 for?
    #dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)
    dZ1 = W2.T.dot(dZ2) * sigmoid_prime(Z1)
    
    dW1 = 1/ m * dZ1.dot(X.T)
    db1 = 1 / m * np.sum(dZ1)

    return dW1, db1, dW2, db2

def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):#here is alpha the learning rate
    W1 = W1 - alpha * dW1
    b1 = b1 - alpha * db1
    W2 = W2 - alpha * dW2
    b2 = b2 - alpha * db2

    return W1, b1, W2, b2

#25:10


def get_predictions(A2):
    return np.argmax(A2, 0)

def get_confidence(A2):
    return ((max(A2) / 1) * 100)

def get_accuracy(predictions, Y):
    #print(predictions, Y)
    return np.sum(predictions == Y) / Y.size

def gradient_descent(X, Y, iterations, alpha):
    W1, b1, W2, b2 = init_params()
    for i in range(iterations):

        imageMatrix = X[i][:,np.newaxis]
        
        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, imageMatrix)#individual images

        '''print(A2)
        print("AZ above")
        print(one_hot(Y[i]))
        print("one hot above")'''
        
        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, imageMatrix, Y[i])
        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)
        
        #progress updates
        if i % 5000 == 0:
            print("Iteration: ", i)
            print("Accuracy: ", get_accuracy(get_predictions(A2), Y[i]))
            print("Prediction", get_predictions(A2))
            print("Actual", Y[i])
        
    return W1, b1, W2, b2
            #work on getPredictions)
    

W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 50000, 0.1)#500 iterations


def test_image(Xtest, Ytest, index):
    imageMatrix = Xtest[index][:,np.newaxis]
        
    Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, imageMatrix)#individual images

    print(A2)
    print("AZ above")
    print(one_hot(Ytest[index]))
    print("one hot above")  

    print("image number: ", index)
    #print("Accuracy: ", get_accuracy(get_predictions(A2), Y[i]))
    print("Prediction", get_predictions(A2))
    #print("Actual", Ytest[index])
    
def test_image_individual_upload(Xtest):
    imageMatrix = Xtest[:,np.newaxis]
        
    Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, imageMatrix)#individual images

    '''print(A2)
    print("AZ above")
    print(one_hot(Ytest[index]))
    print("one hot above")  '''

    #print("image number: ", index)
    #print("Accuracy: ", get_accuracy(get_predictions(A2), Y[i]))
    print("Prediction for uploaded image", get_predictions(A2))
    print("Percent Confidence", round(get_confidence(A2)[0]))
    #print("Actual", Ytest[index])


#test_image(X_dev, Y_dev, 1)
#test_image(X_dev, Y_dev, 2)
#test_image(X_dev, Y_dev, 200)
    

def find_test_image_accuracy(Xtest, Ytest, sizeOfTest, atot):
    
    for i in range(sizeOfTest):

        imageMatrix = Xtest[i][:,np.newaxis]
        
        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, imageMatrix)#individual images

        atot = atot + get_accuracy(get_predictions(A2), Ytest[i])
        
        
    return (atot / sizeOfTest)

accTot = 0.0

acc = find_test_image_accuracy(X_dev, Y_dev, 5000, accTot)
    
print(acc)

print("BIG TEST BELOW!")
print("Testing a 3")
test_image_individual_upload(image3array)
print("Testing a 4")
test_image_individual_upload(image4array)
print("Testing an 8")
test_image_individual_upload(image8array)





